{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Noise Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Longest Common Subsequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LCS(seq1, seq2):\n",
    "    \"\"\"\n",
    "    Initialise a DP array of len(seq2)+1 columns and len(seq1)+1 rows\n",
    "    the extra column and row is to denote the empty sequence as a base case\n",
    "    \"\"\"\n",
    "    dp = [[0 for j in range(len(seq2)+1)] for i in range(len(seq1)+1)]\n",
    "\n",
    "    # Starting from the bottom right most cell and moving from right to left, start the bottom up approach\n",
    "    for i in range(len(seq1)-1,-1,-1):\n",
    "        for j in range(len(seq2)-1,-1,-1):\n",
    "            # If the elements of seq1 and seq2 match, store a 1 + value at the diagonal cell\n",
    "            # Store 1 because the elements match\n",
    "            # Get value from diagonal cell because both elements match so our subproblem moves (i+1,j+1)\n",
    "            if seq1[i]==seq2[j]:\n",
    "                dp[i][j] = 1 + dp[i+1][j+1]\n",
    "            # If the elements of seq1 and seq2 do not match, get the value from its right or bottom cell, taking the max\n",
    "            # We do this to get the max longest common sub sequence of our sub problems after moving (i+1,j) or (i,j+1)\n",
    "            else:\n",
    "                dp[i][j] = max(dp[i][j+1], dp[i+1][j])\n",
    "    # The very first element stores the LCS for the 2 full sequences, building up its value in the bottom up approach\n",
    "    return dp[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LCS('abcde','ace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LCS_return_seq(seq1, seq2):\n",
    "    \"\"\"\n",
    "    Initialise a DP array of len(seq2)+1 columns and len(seq1)+1 rows\n",
    "    the extra column and row is to denote the empty sequence as a base case\n",
    "    \"\"\"\n",
    "    dp = [[0 for j in range(len(seq2)+1)] for i in range(len(seq1)+1)]\n",
    "    # Fill up the DP array where each cell contains the LCS of the subproblems\n",
    "    # Starting from the bottom right most cell and moving from right to left, start the bottom up approach\n",
    "    for i in range(len(seq1)-1,-1,-1):\n",
    "        for j in range(len(seq2)-1,-1,-1):\n",
    "            # If the elements of seq1 and seq2 match, store a 1 + value at the diagonal cell\n",
    "            # Store 1 because the elements match\n",
    "            # Get value from diagonal cell because both elements match so our subproblem moves (i+1,j+1)\n",
    "            if seq1[i]==seq2[j]:\n",
    "                dp[i][j] = 1 + dp[i+1][j+1]\n",
    "            # If the elements of seq1 and seq2 do not match, get the value from its right or bottom cell, taking the max\n",
    "            # We do this to get the max longest common sub sequence of our sub problems after moving (i+1,j) or (i,j+1)\n",
    "            else:\n",
    "                dp[i][j] = max(dp[i][j+1], dp[i+1][j])\n",
    "    \n",
    "    # Get the actual subsequence\n",
    "    # Re-initialise the pointers\n",
    "    i = 0\n",
    "    j = 0\n",
    "    lcs = []\n",
    "\n",
    "    while i < len(seq1) and j < len(seq2):\n",
    "        # If the characters match at those positions, add the character\n",
    "        if seq1[i]==seq2[j]:\n",
    "            lcs.append(seq1[i])\n",
    "            # Move diagonally as our subproblem now becomes i+1,j+1\n",
    "            i+=1\n",
    "            j+=1\n",
    "        # If the characters don't match at that cell, we try going to the cell\n",
    "        # with the greater value (either the right or down cell which are our subproblems)\n",
    "        # We go to the cell with the greater value because a match was found on or near that cell\n",
    "        elif dp[i+1][j]>=dp[i][j+1]:\n",
    "            i+=1\n",
    "        else:\n",
    "            j+=1\n",
    "\n",
    "    return lcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'c', 'e']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LCS_return_seq('abcde','ace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'enjoys', 'listening', 'music']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq1 = [\"I\", \"enjoys\", \"listening\", \"to\", \"music\"]\n",
    "seq2 = [\"I\", \"am\", \"enjoys\", \"listening\", \"music\"]\n",
    "LCS_return_seq(seq1,seq2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning 2 sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_align(seq1,seq2):\n",
    "    # Get the lcs between the 2 sequences\n",
    "    lcs = LCS_return_seq(seq1, seq2)\n",
    "\n",
    "    seq1_aligned = []\n",
    "    seq2_aligned = []\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "\n",
    "    padding = \"Pad\"\n",
    "    next_x = False\n",
    "\n",
    "    \"\"\"\n",
    "    Big Idea: \n",
    "    - align the lcs tokens\n",
    "    - for the out-of-lcs token in one sequence, align it with a padding token in the other sequence \n",
    "      to denote token level noise\n",
    "    \"\"\"\n",
    "    for x in lcs:\n",
    "        next_x = False\n",
    "        while not next_x:\n",
    "\n",
    "            # Case 1: seq1[i]==seq2[j]==x\n",
    "            # Action\n",
    "            # - append seq[i] to seq1_aligned\n",
    "            # - append seq[j] to seq2_aligned\n",
    "            # - i+1\n",
    "            # - j+1\n",
    "            if seq1[i]==x and seq2[j]==x:\n",
    "                seq1_aligned.append(seq1[i])\n",
    "                seq2_aligned.append(seq2[j])\n",
    "                i+=1\n",
    "                j+=1\n",
    "                # Move to the next x in lcs\n",
    "                next_x = True\n",
    "\n",
    "            # Case 2: seq1[i]==x but seq[2]!=x\n",
    "            # Action\n",
    "            # - append padding to seq1_aligned to match the out-of-lcs token from seq2\n",
    "            # - append out-of-lcs token seq2[j] to seq2_aligned\n",
    "            # - j+1 to simulate that the j-th token has been matched by the padding token in seq1\n",
    "            elif seq1[i]==x and seq2[j]!=x:\n",
    "                seq1_aligned.append(padding)\n",
    "                seq2_aligned.append(seq2[j])\n",
    "                j+=1\n",
    "\n",
    "            # Case 3 and 4: seq1[i]!=x but seq[2]==x as well as seq1[i]!=x but seq[2]!=x\n",
    "            # Action\n",
    "            # - append out-of-lcs token seq1[i] to seq1_aligned\n",
    "            # - append padding to seq2_aligned to match the out-of-lcs token from seq1\n",
    "            # - i+1 to simulate that the i-th token has been matched by the padding token in seq2\n",
    "            # For the case where both don't match, we use the same logic. It'll result\n",
    "            # in matched padding to out-of-lcs tokens in both seqs\n",
    "            else:\n",
    "                seq1_aligned.append(seq1[i])\n",
    "                seq2_aligned.append(padding)\n",
    "                i+=1\n",
    "\n",
    "    # Once all the lcs tokens have been aligned\n",
    "    # for the out-of-lcs token in one sequence, align it with a padding token in the other sequence\n",
    "    while i < len(seq1):\n",
    "        seq1_aligned.append(seq1[i])\n",
    "        seq2_aligned.append(padding)\n",
    "        i+=1\n",
    "\n",
    "    while j < len(seq2):\n",
    "        seq1_aligned.append(padding)\n",
    "        seq2_aligned.append(seq2[j])\n",
    "        j+=1\n",
    "\n",
    "    return seq1_aligned, seq2_aligned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Case where 1 col doesn't match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'j', 'Pad', 'Pad', 'c', 'd', 'e']\n",
      "['a', 'Pad', 'z', 'b', 'c', 'Pad', 'e']\n"
     ]
    }
   ],
   "source": [
    "# Case where one col doesn't match\n",
    "seq1 = ['a','j','c','d','e']\n",
    "seq2 = ['a','z','b','c','e']\n",
    "seq1_aligned, seq2_aligned = force_align(seq1,seq2)\n",
    "print(seq1_aligned)\n",
    "print(seq2_aligned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing 2 Sequences using the given example**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Given example**\n",
    "\n",
    "Input:\n",
    "\n",
    "```\n",
    "1. a b c d e\n",
    "2. a b c e\n",
    "3. a b c d e\n",
    "4. a b c e\n",
    "5. a z b c e\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "\n",
    "```\n",
    "1. a pad b c d   e\n",
    "2. a pad b c pad e\n",
    "3. a pad b c d   e\n",
    "4. a pad b c pad e\n",
    "5. a z   b c pad e\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e']\n",
      "['a', 'b', 'c', 'Pad', 'e']\n"
     ]
    }
   ],
   "source": [
    "# 1 and 2\n",
    "seq1 = ['a','b','c','d','e']\n",
    "seq2 = ['a','b','c','e']\n",
    "seq1_aligned, seq2_aligned = force_align(seq1,seq2)\n",
    "print(seq1_aligned)\n",
    "print(seq2_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'Pad', 'b', 'Pad', 'c', 'd', 'e']\n",
      "['a', 'z', 'b', 'g', 'c', 'Pad', 'e']\n"
     ]
    }
   ],
   "source": [
    "# 1 and random case\n",
    "seq1 = ['a','b','c','d','e']\n",
    "seq2 = ['a','z','b','g','c','e']\n",
    "seq1_aligned, seq2_aligned = force_align(seq1,seq2)\n",
    "print(seq1_aligned)\n",
    "print(seq2_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'Pad', 'b', 'c', 'd', 'e']\n",
      "['a', 'z', 'b', 'c', 'Pad', 'e']\n"
     ]
    }
   ],
   "source": [
    "# 1 and 5\n",
    "seq1 = ['a','b','c','d','e']\n",
    "seq2 = ['a','z','b','c','e']\n",
    "seq1_aligned, seq2_aligned = force_align(seq1,seq2)\n",
    "print(seq1_aligned)\n",
    "print(seq2_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'Pad', 'b', 'c', 'd', 'e']\n",
      "['a', 'Pad', 'b', 'c', 'Pad', 'e']\n"
     ]
    }
   ],
   "source": [
    "# 1 (after 5) and 2\n",
    "seq1 = ['a', 'Pad', 'b', 'c', 'd', 'e']\n",
    "seq2 = ['a','b','c','e']\n",
    "seq1_aligned, seq2_aligned = force_align(seq1,seq2)\n",
    "print(seq1_aligned)\n",
    "print(seq2_aligned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning N hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What if we have a case where we have 2 different LCS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq1 = ['a','q','c','r','e']\n",
    "seq2 = ['a','s','c','t','e']\n",
    "seq3 = ['a','u','g','v','p','b','e']\n",
    "seq4 = ['a','z','w','g','p','x','e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'q', 'Pad', 'c', 'r', 'Pad', 'e']\n",
      "['a', 'Pad', 's', 'c', 'Pad', 't', 'e']\n"
     ]
    }
   ],
   "source": [
    "seq1_aligned, seq2_aligned = force_align(seq1,seq2)\n",
    "print(seq1_aligned)\n",
    "print(seq2_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'q', 'c', 'r', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'e']\n",
      "['a', 'Pad', 'Pad', 'Pad', 'u', 'g', 'v', 'p', 'b', 'e']\n"
     ]
    }
   ],
   "source": [
    "seq1_aligned, seq2_aligned = force_align(seq1,seq3)\n",
    "print(seq1_aligned)\n",
    "print(seq2_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'u', 'Pad', 'Pad', 'g', 'v', 'p', 'b', 'Pad', 'e']\n",
      "['a', 'Pad', 'z', 'w', 'g', 'Pad', 'p', 'Pad', 'x', 'e']\n"
     ]
    }
   ],
   "source": [
    "seq1_aligned, seq2_aligned = force_align(seq3,seq4)\n",
    "print(seq1_aligned)\n",
    "print(seq2_aligned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach**:\n",
    "\n",
    "Step 1:\n",
    "\n",
    "Align sequence 1 and sequence 2. We get:\n",
    "```\n",
    "seq1 = ['a', 'q', 'Pad', 'c', 'r', 'Pad', 'e']\n",
    "seq2 = ['a', 'Pad', 's', 'c', 'Pad', 't', 'e']\n",
    "```\n",
    "\n",
    "Step 2:\n",
    "\n",
    "Extract the tokens from the aligned sequence. This will help align the new sequence properly to both sequence 1 and sequence 2:\n",
    "```\n",
    "seq_intersection = ['a', 'q', 's', 'c', 'r', 't', 'e']\n",
    "```\n",
    "\n",
    "Step 3:\n",
    "\n",
    "Align the new sequence to the seq_intersection of the results. \n",
    "\n",
    "This ensures that we align the new sequence with all other sequences in the results:\n",
    "```\n",
    "seq_intersection = ['a', 'q', 's', 'c', 'r', 't', 'e']\n",
    "seq3 = ['a','u','g','v','p','b','e']\n",
    "```\n",
    "\n",
    "The result is:\n",
    "```\n",
    "seq_intersection = ['a', 'q', 's', 'c', 'r', 't', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'e']\n",
    "seq3 = ['a', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'u', 'g', 'v', 'p', 'b', 'e']\n",
    "```\n",
    "\n",
    "Step 4:\n",
    "\n",
    "Re-align sequence 1 and sequence 2 by inserting 'Pad' tokens at where they were inserted in the seq_intersection\n",
    "\n",
    "This is because that is the padding required to be added to sequence 1 and sequence 2\n",
    "\n",
    "\n",
    "seq1      = ['a', 'q', 'Pad', 'c', 'r', 'Pad',                                       'e'] (index i)\n",
    "seq2      = ['a', 'Pad', 's', 'c', 'Pad', 't',                                       'e'] (index j)\n",
    "token_seq = ['a', 'q', 's', 'c', 'r', 't',        'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'e'] (index k)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_new_seq(results,new_seq):\n",
    "    # Get the intersection of the sequences i.e. only the tokens and no padding tokens\n",
    "    seq_intersection = []\n",
    "    # For each column in the aligned sequences in the results,\n",
    "    # get the non-padding token, which is the same throughout the column\n",
    "    for col in zip(*results):\n",
    "        tokens = [t for t in col if t != 'Pad']\n",
    "        seq_intersection.append(tokens[0])\n",
    "\n",
    "    print(\"Results\")\n",
    "    for res in results:\n",
    "        print(res)\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "    print(\"Sequence Intersection: \")\n",
    "    print(seq_intersection)\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"New Sequence:\")\n",
    "    print(new_seq)\n",
    "    print(\"\")\n",
    "\n",
    "    # Align the new sequence with the sequence intersection of the results. This ensures that we align the new sequence\n",
    "    # with all other sequences in the results\n",
    "    seq_intersection_aligned, new_seq_aligned = force_align(seq_intersection,new_seq)\n",
    "\n",
    "    print(\"Sequence Intersection aligned: \")\n",
    "    print(seq_intersection_aligned)\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"New Sequence Aligned:\")\n",
    "    print(new_seq_aligned)\n",
    "    print(\"\")\n",
    "\n",
    "    # Initialise the column pointer\n",
    "    col_pointer = 0\n",
    "    # Initialise the newly aligned results\n",
    "    aligned_results = [[] for _ in range(len(results))] \n",
    "\n",
    "    # For each token in the aligned sequence intersection\n",
    "    for k in range(len(seq_intersection_aligned)):\n",
    "        # If the token in the aligned sequence intersection was a padding token, add it to the rest of the results to align them\n",
    "        if seq_intersection_aligned[k]=='Pad':\n",
    "            for i in range(len(results)):\n",
    "                 aligned_results[i].append('Pad')\n",
    "        # If not, add the current elements from the col in the results as they are still aligned with the new sequence intersection\n",
    "        # move the column pointer as well\n",
    "        else:\n",
    "            for i in range(len(results)):\n",
    "                 aligned_results[i].append(results[i][col_pointer])\n",
    "            col_pointer+=1\n",
    "\n",
    "    \n",
    "    aligned_results.append(new_seq_aligned)\n",
    "\n",
    "    print(\"Aligned Results\")\n",
    "    for res in aligned_results:\n",
    "        print(res)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "\n",
    "    return aligned_results\n",
    "\n",
    "\n",
    "def force_align_n_seqs(seqs):\n",
    "    # First force align 2 sequences\n",
    "    seq1,seq2 = force_align(seqs[0],seqs[1])\n",
    "\n",
    "    result = [seq1,seq2]\n",
    "\n",
    "    # Next, force align the sequences progressively\n",
    "    for seq in seqs[2:]:\n",
    "        result = align_new_seq(result,seq)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Case 1 using cases of an LCS between seq1 and seq2, as well as between seq3 and seq4, and common seq between all 3**\n",
    "\n",
    "```\n",
    "seq1 = ['a','q','c','r','e']\n",
    "seq2 = ['a','s','c','t','e']\n",
    "\n",
    "seq3 = ['a','u','g','v','p','b','e']\n",
    "seq4 = ['a','z','w','g','p','x','e']\n",
    "```\n",
    "\n",
    "The LCS between seq1 and seq2 are: a c e\n",
    "\n",
    "The LCS between seq3 and seq4 are: a g p e\n",
    "\n",
    "the LCS between all seqs are: a e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results\n",
      "['a', 'q', 'Pad', 'c', 'r', 'Pad', 'e']\n",
      "['a', 'Pad', 's', 'c', 'Pad', 't', 'e']\n",
      "\n",
      "Sequence Intersection: \n",
      "['a', 'q', 's', 'c', 'r', 't', 'e']\n",
      "\n",
      "New Sequence:\n",
      "['a', 'u', 'g', 'v', 'p', 'b', 'e']\n",
      "\n",
      "Sequence Intersection aligned: \n",
      "['a', 'q', 's', 'c', 'r', 't', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'e']\n",
      "\n",
      "New Sequence Aligned:\n",
      "['a', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'u', 'g', 'v', 'p', 'b', 'e']\n",
      "\n",
      "Aligned Results\n",
      "['a', 'q', 'Pad', 'c', 'r', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'e']\n",
      "['a', 'Pad', 's', 'c', 'Pad', 't', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'e']\n",
      "['a', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'u', 'g', 'v', 'p', 'b', 'e']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Results\n",
      "['a', 'q', 'Pad', 'c', 'r', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'e']\n",
      "['a', 'Pad', 's', 'c', 'Pad', 't', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'e']\n",
      "['a', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'u', 'g', 'v', 'p', 'b', 'e']\n",
      "\n",
      "Sequence Intersection: \n",
      "['a', 'q', 's', 'c', 'r', 't', 'u', 'g', 'v', 'p', 'b', 'e']\n",
      "\n",
      "New Sequence:\n",
      "['a', 'z', 'w', 'g', 'p', 'x', 'e']\n",
      "\n",
      "Sequence Intersection aligned: \n",
      "['a', 'q', 's', 'c', 'r', 't', 'u', 'Pad', 'Pad', 'g', 'v', 'p', 'b', 'Pad', 'e']\n",
      "\n",
      "New Sequence Aligned:\n",
      "['a', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'z', 'w', 'g', 'Pad', 'p', 'Pad', 'x', 'e']\n",
      "\n",
      "Aligned Results\n",
      "['a', 'q', 'Pad', 'c', 'r', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'e']\n",
      "['a', 'Pad', 's', 'c', 'Pad', 't', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'e']\n",
      "['a', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'u', 'Pad', 'Pad', 'g', 'v', 'p', 'b', 'Pad', 'e']\n",
      "['a', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'z', 'w', 'g', 'Pad', 'p', 'Pad', 'x', 'e']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seq1 = ['a','q','c','r','e']\n",
    "seq2 = ['a','s','c','t','e']\n",
    "seq3 = ['a','u','g','v','p','b','e']\n",
    "seq4 = ['a','z','w','g','p','x','e']\n",
    "seqs = [seq1,seq2,seq3,seq4]\n",
    "results = force_align_n_seqs(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "['a', 'q', 'c', 'r', 'e']\n",
      "['a', 's', 'c', 't', 'e']\n",
      "['a', 'u', 'g', 'v', 'p', 'b', 'e']\n",
      "['a', 'z', 'w', 'g', 'p', 'x', 'e']\n",
      "\n",
      "Output:\n",
      "['a', 'q', 'Pad', 'c', 'r', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'e']\n",
      "['a', 'Pad', 's', 'c', 'Pad', 't', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'e']\n",
      "['a', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'u', 'Pad', 'Pad', 'g', 'v', 'p', 'b', 'Pad', 'e']\n",
      "['a', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'Pad', 'z', 'w', 'g', 'Pad', 'p', 'Pad', 'x', 'e']\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\")\n",
    "for seq in seqs:\n",
    "    print(seq)\n",
    "print(\"\")\n",
    "print(\"Output:\")\n",
    "for seq in results:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Case 2 using the given example**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Given example**\n",
    "\n",
    "Input:\n",
    "\n",
    "```\n",
    "1. a b c d e\n",
    "2. a b c e\n",
    "3. a b c d e\n",
    "4. a b c e\n",
    "5. a z b c e\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "\n",
    "```\n",
    "1. a pad b c d   e\n",
    "2. a pad b c pad e\n",
    "3. a pad b c d   e\n",
    "4. a pad b c pad e\n",
    "5. a z   b c pad e\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results\n",
      "['a', 'b', 'c', 'd', 'e']\n",
      "['a', 'b', 'c', 'Pad', 'e']\n",
      "\n",
      "Sequence Intersection: \n",
      "['a', 'b', 'c', 'd', 'e']\n",
      "\n",
      "New Sequence:\n",
      "['a', 'b', 'c', 'd', 'e']\n",
      "\n",
      "Sequence Intersection aligned: \n",
      "['a', 'b', 'c', 'd', 'e']\n",
      "\n",
      "New Sequence Aligned:\n",
      "['a', 'b', 'c', 'd', 'e']\n",
      "\n",
      "Aligned Results\n",
      "['a', 'b', 'c', 'd', 'e']\n",
      "['a', 'b', 'c', 'Pad', 'e']\n",
      "['a', 'b', 'c', 'd', 'e']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Results\n",
      "['a', 'b', 'c', 'd', 'e']\n",
      "['a', 'b', 'c', 'Pad', 'e']\n",
      "['a', 'b', 'c', 'd', 'e']\n",
      "\n",
      "Sequence Intersection: \n",
      "['a', 'b', 'c', 'd', 'e']\n",
      "\n",
      "New Sequence:\n",
      "['a', 'b', 'c', 'e']\n",
      "\n",
      "Sequence Intersection aligned: \n",
      "['a', 'b', 'c', 'd', 'e']\n",
      "\n",
      "New Sequence Aligned:\n",
      "['a', 'b', 'c', 'Pad', 'e']\n",
      "\n",
      "Aligned Results\n",
      "['a', 'b', 'c', 'd', 'e']\n",
      "['a', 'b', 'c', 'Pad', 'e']\n",
      "['a', 'b', 'c', 'd', 'e']\n",
      "['a', 'b', 'c', 'Pad', 'e']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Results\n",
      "['a', 'b', 'c', 'd', 'e']\n",
      "['a', 'b', 'c', 'Pad', 'e']\n",
      "['a', 'b', 'c', 'd', 'e']\n",
      "['a', 'b', 'c', 'Pad', 'e']\n",
      "\n",
      "Sequence Intersection: \n",
      "['a', 'b', 'c', 'd', 'e']\n",
      "\n",
      "New Sequence:\n",
      "['a', 'z', 'b', 'c', 'e']\n",
      "\n",
      "Sequence Intersection aligned: \n",
      "['a', 'Pad', 'b', 'c', 'd', 'e']\n",
      "\n",
      "New Sequence Aligned:\n",
      "['a', 'z', 'b', 'c', 'Pad', 'e']\n",
      "\n",
      "Aligned Results\n",
      "['a', 'Pad', 'b', 'c', 'd', 'e']\n",
      "['a', 'Pad', 'b', 'c', 'Pad', 'e']\n",
      "['a', 'Pad', 'b', 'c', 'd', 'e']\n",
      "['a', 'Pad', 'b', 'c', 'Pad', 'e']\n",
      "['a', 'z', 'b', 'c', 'Pad', 'e']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seq1 = ['a','b','c','d','e']\n",
    "seq2 = ['a','b','c','e']\n",
    "seq3 = ['a','b','c','d','e']\n",
    "seq4 = ['a','b','c','e']\n",
    "seq5 = ['a','z','b','c','e']\n",
    "seqs = [seq1,seq2,seq3,seq4,seq5]\n",
    "results = force_align_n_seqs(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "['a', 'b', 'c', 'd', 'e']\n",
      "['a', 'b', 'c', 'e']\n",
      "['a', 'b', 'c', 'd', 'e']\n",
      "['a', 'b', 'c', 'e']\n",
      "['a', 'z', 'b', 'c', 'e']\n",
      "\n",
      "Output:\n",
      "['a', 'Pad', 'b', 'c', 'd', 'e']\n",
      "['a', 'Pad', 'b', 'c', 'Pad', 'e']\n",
      "['a', 'Pad', 'b', 'c', 'd', 'e']\n",
      "['a', 'Pad', 'b', 'c', 'Pad', 'e']\n",
      "['a', 'z', 'b', 'c', 'Pad', 'e']\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\")\n",
    "for seq in seqs:\n",
    "    print(seq)\n",
    "print(\"\")\n",
    "print(\"Output:\")\n",
    "for seq in results:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lang-Space Noise Embedding: Extract token-level noise embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing the actual token level noise embedding\n",
    "\n",
    "- Replace the characters with token embeddings \n",
    "- Replace equality with similarity\n",
    "- SBERT is used to extract the token embedding\n",
    "\n",
    "Actual Sequences\n",
    "\n",
    "```\n",
    "[\"I\", \"enjoys\", \"listening\", \"to\", \"music\"]\n",
    "[\"I\", \"enjoy\", \"listen\", \"music\"]\n",
    "[\"I\", \"join\", \"listening\", \"to\", \"music\"]\n",
    "[\"I\", \"enjoy\", \"listened\", \"mystic\"]\n",
    "[\"I\", \"am\", \"join\", \"listening\", \"music\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jellyfish\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "def similar_syntax_ver1(w1,w2,l1,threshold):\n",
    "    \"\"\"\n",
    "    Uses the indel similarity between the words and the indel similarity between the approx phonetic representations of the words\n",
    "    \"\"\"\n",
    "    sim = l1*fuzz.ratio(w1,w2) + (1-l1)*fuzz.ratio(jellyfish.metaphone(w1),jellyfish.metaphone(w2))\n",
    "    if sim > threshold:\n",
    "        print(f\"{w1} and {w2} are similar with a score of {sim}\")\n",
    "        print(f\"The indel similarity between words is {fuzz.ratio(w1,w2)}\")\n",
    "        print(f\"The indel similarity between their phonetics is {fuzz.ratio(jellyfish.metaphone(w1),jellyfish.metaphone(w2))}\")\n",
    "        print(\"\")\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jellyfish\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "def similar_syntax_ver2(w1,w2,threshold):\n",
    "    \"\"\"\n",
    "    Uses the indel similarity between the words \n",
    "    \"\"\"\n",
    "    sim = fuzz.ratio(w1,w2) \n",
    "\n",
    "    return sim\n",
    "\n",
    "    if sim > threshold:\n",
    "        #print(f\"{w1} and {w2} are similar with a score of {sim}\")\n",
    "        #print(\"\")\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz.distance import Levenshtein\n",
    "\n",
    "def similar_syntax_ver3(w1,w2,threshold):\n",
    "    \"\"\"\n",
    "    Uses the Levenshtein similarity between the words\n",
    "    \"\"\"\n",
    "    sim = Levenshtein.normalized_similarity(w1,w2)*100\n",
    "\n",
    "    return sim\n",
    "    if sim > threshold:\n",
    "        #print(f\"{w1} and {w2} are similar with a score of {sim}\")\n",
    "        #print(\"\")\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LCS_ver1(seq1, seq2, l1,threshold):\n",
    "    \"\"\"\n",
    "    Initialise a DP array of len(seq2)+1 columns and len(seq1)+1 rows\n",
    "    the extra column and row is to denote the empty sequence as a base case\n",
    "    \"\"\"\n",
    "    dp = [[0 for j in range(len(seq2)+1)] for i in range(len(seq1)+1)]\n",
    "    # Fill up the DP array where each cell contains the LCS of the subproblems\n",
    "    # Starting from the bottom right most cell and moving from right to left, start the bottom up approach\n",
    "    for i in range(len(seq1)-1,-1,-1):\n",
    "        for j in range(len(seq2)-1,-1,-1):\n",
    "            # If the elements of seq1 and seq2 match, store a 1 + value at the diagonal cell\n",
    "            # Store 1 because the elements match\n",
    "            # Get value from diagonal cell because both elements match so our subproblem moves (i+1,j+1)\n",
    "            if similar_syntax_ver1(seq1[i],seq2[j],l1,threshold):\n",
    "                dp[i][j] = 1 + dp[i+1][j+1]\n",
    "            # If the elements of seq1 and seq2 do not match, get the value from its right or bottom cell, taking the max\n",
    "            # We do this to get the max longest common sub sequence of our sub problems after moving (i+1,j) or (i,j+1)\n",
    "            else:\n",
    "                dp[i][j] = max(dp[i][j+1], dp[i+1][j])\n",
    "    \n",
    "    # Get the actual subsequence\n",
    "    # Re-initialise the pointers\n",
    "    i = 0\n",
    "    j = 0\n",
    "    lcs = []\n",
    "\n",
    "    while i < len(seq1) and j < len(seq2):\n",
    "        # If the characters match at those positions, add the character\n",
    "        if similar_syntax_ver1(seq1[i],seq2[j],l1,threshold):\n",
    "            # By default, we take the word from sequence 1. \n",
    "            # Note that although the corresponding word in sequence 2 may be different, it is still\n",
    "            # syntactically different\n",
    "            lcs.append(seq1[i]) \n",
    "            # Move diagonally as our subproblem now becomes i+1,j+1\n",
    "            i+=1\n",
    "            j+=1\n",
    "        # If the characters don't match at that cell, we try going to the cell\n",
    "        # with the greater value (either the right or down cell which are our subproblems)\n",
    "        # We go to the cell with the greater value because a match was found on or near that cell\n",
    "        elif dp[i+1][j]>=dp[i][j+1]:\n",
    "            i+=1\n",
    "        else:\n",
    "            j+=1\n",
    "\n",
    "    return lcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LCS_ver2(seq1, seq2,threshold):\n",
    "    \"\"\"\n",
    "    Initialise a DP array of len(seq2)+1 columns and len(seq1)+1 rows\n",
    "    the extra column and row is to denote the empty sequence as a base case\n",
    "    \"\"\"\n",
    "    dp = [[0 for j in range(len(seq2)+1)] for i in range(len(seq1)+1)]\n",
    "    # Fill up the DP array where each cell contains the LCS of the subproblems\n",
    "    # Starting from the bottom right most cell and moving from right to left, start the bottom up approach\n",
    "    for i in range(len(seq1)-1,-1,-1):\n",
    "        for j in range(len(seq2)-1,-1,-1):\n",
    "            # If the elements of seq1 and seq2 match, store a 1 + value at the diagonal cell\n",
    "            # Store 1 because the elements match\n",
    "            # Get value from diagonal cell because both elements match so our subproblem moves (i+1,j+1)\n",
    "            if similar_syntax_ver2(seq1[i],seq2[j],threshold):\n",
    "                dp[i][j] = 1 + dp[i+1][j+1]\n",
    "            # If the elements of seq1 and seq2 do not match, get the value from its right or bottom cell, taking the max\n",
    "            # We do this to get the max longest common sub sequence of our sub problems after moving (i+1,j) or (i,j+1)\n",
    "            else:\n",
    "                dp[i][j] = max(dp[i][j+1], dp[i+1][j])\n",
    "    \n",
    "    # Get the actual subsequence\n",
    "    # Re-initialise the pointers\n",
    "    i = 0\n",
    "    j = 0\n",
    "    lcs = []\n",
    "\n",
    "    while i < len(seq1) and j < len(seq2):\n",
    "        # If the characters match at those positions, add the character\n",
    "        if similar_syntax_ver2(seq1[i],seq2[j],threshold):\n",
    "            # By default, we take the word from sequence 1. \n",
    "            # Note that although the corresponding word in sequence 2 may be different, it is still\n",
    "            # syntactically different\n",
    "            lcs.append(seq1[i]) \n",
    "            # Move diagonally as our subproblem now becomes i+1,j+1\n",
    "            i+=1\n",
    "            j+=1\n",
    "        # If the characters don't match at that cell, we try going to the cell\n",
    "        # with the greater value (either the right or down cell which are our subproblems)\n",
    "        # We go to the cell with the greater value because a match was found on or near that cell\n",
    "        elif dp[i+1][j]>=dp[i][j+1]:\n",
    "            i+=1\n",
    "        else:\n",
    "            j+=1\n",
    "\n",
    "    return lcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LCS_ver3(seq1, seq2,threshold):\n",
    "    \"\"\"\n",
    "    Initialise a DP array of len(seq2)+1 columns and len(seq1)+1 rows\n",
    "    the extra column and row is to denote the empty sequence as a base case\n",
    "    \"\"\"\n",
    "    dp = [[0 for j in range(len(seq2)+1)] for i in range(len(seq1)+1)]\n",
    "    # Fill up the DP array where each cell contains the LCS of the subproblems\n",
    "    # Starting from the bottom right most cell and moving from right to left, start the bottom up approach\n",
    "    for i in range(len(seq1)-1,-1,-1):\n",
    "        for j in range(len(seq2)-1,-1,-1):\n",
    "            # If the elements of seq1 and seq2 match, store a 1 + value at the diagonal cell\n",
    "            # Store 1 because the elements match\n",
    "            # Get value from diagonal cell because both elements match so our subproblem moves (i+1,j+1)\n",
    "            if similar_syntax_ver3(seq1[i],seq2[j],threshold):\n",
    "                dp[i][j] = 1 + dp[i+1][j+1]\n",
    "            # If the elements of seq1 and seq2 do not match, get the value from its right or bottom cell, taking the max\n",
    "            # We do this to get the max longest common sub sequence of our sub problems after moving (i+1,j) or (i,j+1)\n",
    "            else:\n",
    "                dp[i][j] = max(dp[i][j+1], dp[i+1][j])\n",
    "    \n",
    "    # Get the actual subsequence\n",
    "    # Re-initialise the pointers\n",
    "    i = 0\n",
    "    j = 0\n",
    "    lcs = []\n",
    "\n",
    "    while i < len(seq1) and j < len(seq2):\n",
    "        # If the characters match at those positions, add the character\n",
    "        if similar_syntax_ver3(seq1[i],seq2[j],threshold):\n",
    "            # By default, we take the word from sequence 1. \n",
    "            # Note that although the corresponding word in sequence 2 may be different, it is still\n",
    "            # syntactically different\n",
    "            lcs.append(seq1[i]) \n",
    "            # Move diagonally as our subproblem now becomes i+1,j+1\n",
    "            i+=1\n",
    "            j+=1\n",
    "        # If the characters don't match at that cell, we try going to the cell\n",
    "        # with the greater value (either the right or down cell which are our subproblems)\n",
    "        # We go to the cell with the greater value because a match was found on or near that cell\n",
    "        elif dp[i+1][j]>=dp[i][j+1]:\n",
    "            i+=1\n",
    "        else:\n",
    "            j+=1\n",
    "\n",
    "    return lcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test LCS for sequences**\n",
    "\n",
    "```\n",
    "[\"I\", \"enjoys\", \"listening\", \"to\", \"music\"]\n",
    "[\"I\", \"enjoy\", \"listen\", \"music\"]\n",
    "[\"I\", \"join\", \"listening\", \"to\", \"music\"]\n",
    "[\"I\", \"enjoy\", \"listened\", \"mystic\"]\n",
    "[\"I\", \"am\", \"join\", \"listening\", \"music\"]\n",
    "```\n",
    "\n",
    "Note: Although the corresponding word in sequence 2 may be different, it is still syntactically different.\n",
    "\n",
    "Our choice of retrieving the common word from sequence 1 is arbitrary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing for weightage with indel similarity between words <u>and</u> indel similarity between phonetic representations with a threshold of .35 amd .3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "music and music are similar with a score of 100.0\n",
      "The indel similarity between words is 100.0\n",
      "The indel similarity between their phonetics is 100.0\n",
      "\n",
      "music and listening are similar with a score of 36.507936507936506\n",
      "The indel similarity between words is 28.57142857142857\n",
      "The indel similarity between their phonetics is 44.44444444444444\n",
      "\n",
      "listening and music are similar with a score of 36.507936507936506\n",
      "The indel similarity between words is 28.57142857142857\n",
      "The indel similarity between their phonetics is 44.44444444444444\n",
      "\n",
      "listening and listening are similar with a score of 100.0\n",
      "The indel similarity between words is 100.0\n",
      "The indel similarity between their phonetics is 100.0\n",
      "\n",
      "enjoys and join are similar with a score of 36.66666666666667\n",
      "The indel similarity between words is 40.0\n",
      "The indel similarity between their phonetics is 33.333333333333336\n",
      "\n",
      "I and I are similar with a score of 100.0\n",
      "The indel similarity between words is 100.0\n",
      "The indel similarity between their phonetics is 100.0\n",
      "\n",
      "I and I are similar with a score of 100.0\n",
      "The indel similarity between words is 100.0\n",
      "The indel similarity between their phonetics is 100.0\n",
      "\n",
      "enjoys and join are similar with a score of 36.66666666666667\n",
      "The indel similarity between words is 40.0\n",
      "The indel similarity between their phonetics is 33.333333333333336\n",
      "\n",
      "listening and listening are similar with a score of 100.0\n",
      "The indel similarity between words is 100.0\n",
      "The indel similarity between their phonetics is 100.0\n",
      "\n",
      "music and music are similar with a score of 100.0\n",
      "The indel similarity between words is 100.0\n",
      "The indel similarity between their phonetics is 100.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I', 'enjoys', 'listening', 'music']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq1 = [\"I\", \"enjoys\", \"listening\", \"to\", \"music\"]\n",
    "seq2 = [\"I\", \"am\", \"join\", \"listening\", \"music\"]\n",
    "LCS_ver1(seq1,seq2,0.5,35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, it seems like ```enjoys and join``` as well as ```listening and music``` have similar levels of similarity\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "music and music are similar with a score of 100.0\n",
      "The indel similarity between words is 100.0\n",
      "The indel similarity between their phonetics is 100.0\n",
      "\n",
      "music and listening are similar with a score of 36.507936507936506\n",
      "The indel similarity between words is 28.57142857142857\n",
      "The indel similarity between their phonetics is 44.44444444444444\n",
      "\n",
      "music and am are similar with a score of 34.285714285714285\n",
      "The indel similarity between words is 28.57142857142857\n",
      "The indel similarity between their phonetics is 40.0\n",
      "\n",
      "listening and music are similar with a score of 36.507936507936506\n",
      "The indel similarity between words is 28.57142857142857\n",
      "The indel similarity between their phonetics is 44.44444444444444\n",
      "\n",
      "listening and listening are similar with a score of 100.0\n",
      "The indel similarity between words is 100.0\n",
      "The indel similarity between their phonetics is 100.0\n",
      "\n",
      "enjoys and join are similar with a score of 36.66666666666667\n",
      "The indel similarity between words is 40.0\n",
      "The indel similarity between their phonetics is 33.333333333333336\n",
      "\n",
      "I and I are similar with a score of 100.0\n",
      "The indel similarity between words is 100.0\n",
      "The indel similarity between their phonetics is 100.0\n",
      "\n",
      "I and I are similar with a score of 100.0\n",
      "The indel similarity between words is 100.0\n",
      "The indel similarity between their phonetics is 100.0\n",
      "\n",
      "enjoys and join are similar with a score of 36.66666666666667\n",
      "The indel similarity between words is 40.0\n",
      "The indel similarity between their phonetics is 33.333333333333336\n",
      "\n",
      "listening and listening are similar with a score of 100.0\n",
      "The indel similarity between words is 100.0\n",
      "The indel similarity between their phonetics is 100.0\n",
      "\n",
      "music and music are similar with a score of 100.0\n",
      "The indel similarity between words is 100.0\n",
      "The indel similarity between their phonetics is 100.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I', 'enjoys', 'listening', 'music']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq1 = [\"I\", \"enjoys\", \"listening\", \"to\", \"music\"]\n",
    "seq2 = [\"I\", \"am\", \"join\", \"listening\", \"music\"]\n",
    "LCS_ver1(seq1,seq2,0.5,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like indel similarity between words is a better choice from the following results\n",
    "\n",
    "```\n",
    "music and listening are similar with a score of 36.507936507936506\n",
    "The indel similarity between words is 28.57142857142857\n",
    "The indel similarity between their phonetics is 44.44444444444444\n",
    "\n",
    "music and am are similar with a score of 34.285714285714285\n",
    "The indel similarity between words is 28.57142857142857\n",
    "The indel similarity between their phonetics is 40.0\n",
    "\n",
    "enjoys and join are similar with a score of 36.66666666666667\n",
    "The indel similarity between words is 40.0\n",
    "The indel similarity between their phonetics is 33.333333333333336\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing for weightage with indel similarity between words only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "music and music are similar with a score of 100.0\n",
      "The indel similarity between words is 100.0\n",
      "\n",
      "listening and listening are similar with a score of 100.0\n",
      "The indel similarity between words is 100.0\n",
      "\n",
      "enjoys and join are similar with a score of 40.0\n",
      "The indel similarity between words is 40.0\n",
      "\n",
      "I and I are similar with a score of 100.0\n",
      "The indel similarity between words is 100.0\n",
      "\n",
      "I and I are similar with a score of 100.0\n",
      "The indel similarity between words is 100.0\n",
      "\n",
      "enjoys and join are similar with a score of 40.0\n",
      "The indel similarity between words is 40.0\n",
      "\n",
      "listening and listening are similar with a score of 100.0\n",
      "The indel similarity between words is 100.0\n",
      "\n",
      "music and music are similar with a score of 100.0\n",
      "The indel similarity between words is 100.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I', 'enjoys', 'listening', 'music']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq1 = [\"I\", \"enjoys\", \"listening\", \"to\", \"music\"]\n",
    "seq2 = [\"I\", \"am\", \"join\", \"listening\", \"music\"]\n",
    "LCS_ver2(seq1,seq2,35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing for weightage with Levenshtein similarity between words only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "music and music are similar with a score of 100.0\n",
      "\n",
      "listening and listening are similar with a score of 100.0\n",
      "\n",
      "enjoys and join are similar with a score of 33.333333333333336\n",
      "\n",
      "I and I are similar with a score of 100.0\n",
      "\n",
      "I and I are similar with a score of 100.0\n",
      "\n",
      "enjoys and join are similar with a score of 33.333333333333336\n",
      "\n",
      "listening and listening are similar with a score of 100.0\n",
      "\n",
      "music and music are similar with a score of 100.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I', 'enjoys', 'listening', 'music']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq1 = [\"I\", \"enjoys\", \"listening\", \"to\", \"music\"]\n",
    "seq2 = [\"I\", \"am\", \"join\", \"listening\", \"music\"]\n",
    "LCS_ver3(seq1,seq2,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing all pairwise similarities for indel similarity vs levenshtein similarity for our example sequences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq1 = [\"I\", \"enjoys\", \"listening\", \"to\", \"music\"]\n",
    "seq2 = [\"I\", \"enjoy\", \"listen\", \"music\"]\n",
    "seq3 = [\"I\", \"join\", \"listening\", \"to\", \"music\"]\n",
    "seq4 = [\"I\", \"enjoy\", \"listened\", \"mystic\"]\n",
    "seq5 = [\"I\", \"am\", \"join\", \"listening\", \"music\"]\n",
    "\n",
    "all_tokens = set(seq1+seq2+seq3+seq4+seq5)\n",
    "\n",
    "import itertools\n",
    "pairwise = list(itertools.combinations(all_tokens, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair: ('I', 'enjoys')\n",
      "Sim for indel: 0.0\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('I', 'am')\n",
      "Sim for indel: 0.0\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('I', 'mystic')\n",
      "Sim for indel: 0.0\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('I', 'listening')\n",
      "Sim for indel: 0.0\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('I', 'join')\n",
      "Sim for indel: 0.0\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('I', 'music')\n",
      "Sim for indel: 0.0\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('I', 'listen')\n",
      "Sim for indel: 0.0\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('I', 'listened')\n",
      "Sim for indel: 0.0\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('I', 'to')\n",
      "Sim for indel: 0.0\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('I', 'enjoy')\n",
      "Sim for indel: 0.0\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('enjoys', 'am')\n",
      "Sim for indel: 0.0\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('enjoys', 'mystic')\n",
      "Sim for indel: 33.333333333333336\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('enjoys', 'listening')\n",
      "Sim for indel: 26.66666666666667\n",
      "Sim for lev: 11.111111111111116\n",
      "\n",
      "Pair: ('enjoys', 'join')\n",
      "Sim for indel: 40.0\n",
      "Sim for lev: 33.333333333333336\n",
      "\n",
      "Pair: ('enjoys', 'music')\n",
      "Sim for indel: 18.181818181818176\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('enjoys', 'listen')\n",
      "Sim for indel: 33.333333333333336\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('enjoys', 'listened')\n",
      "Sim for indel: 28.57142857142857\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('enjoys', 'to')\n",
      "Sim for indel: 25.0\n",
      "Sim for lev: 16.666666666666664\n",
      "\n",
      "Pair: ('enjoys', 'enjoy')\n",
      "Sim for indel: 90.9090909090909\n",
      "Sim for lev: 83.33333333333334\n",
      "\n",
      "Pair: ('am', 'mystic')\n",
      "Sim for indel: 25.0\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('am', 'listening')\n",
      "Sim for indel: 0.0\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('am', 'join')\n",
      "Sim for indel: 0.0\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('am', 'music')\n",
      "Sim for indel: 28.57142857142857\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('am', 'listen')\n",
      "Sim for indel: 0.0\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('am', 'listened')\n",
      "Sim for indel: 0.0\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('am', 'to')\n",
      "Sim for indel: 0.0\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('am', 'enjoy')\n",
      "Sim for indel: 0.0\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('mystic', 'listening')\n",
      "Sim for indel: 40.0\n",
      "Sim for lev: 33.333333333333336\n",
      "\n",
      "Pair: ('mystic', 'join')\n",
      "Sim for indel: 19.999999999999996\n",
      "Sim for lev: 16.666666666666664\n",
      "\n",
      "Pair: ('mystic', 'music')\n",
      "Sim for indel: 72.72727272727273\n",
      "Sim for lev: 66.66666666666667\n",
      "\n",
      "Pair: ('mystic', 'listen')\n",
      "Sim for indel: 33.333333333333336\n",
      "Sim for lev: 33.333333333333336\n",
      "\n",
      "Pair: ('mystic', 'listened')\n",
      "Sim for indel: 28.57142857142857\n",
      "Sim for lev: 25.0\n",
      "\n",
      "Pair: ('mystic', 'to')\n",
      "Sim for indel: 25.0\n",
      "Sim for lev: 16.666666666666664\n",
      "\n",
      "Pair: ('mystic', 'enjoy')\n",
      "Sim for indel: 18.181818181818176\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('listening', 'join')\n",
      "Sim for indel: 30.76923076923077\n",
      "Sim for lev: 22.22222222222222\n",
      "\n",
      "Pair: ('listening', 'music')\n",
      "Sim for indel: 28.57142857142857\n",
      "Sim for lev: 22.22222222222222\n",
      "\n",
      "Pair: ('listening', 'listen')\n",
      "Sim for indel: 80.0\n",
      "Sim for lev: 66.66666666666667\n",
      "\n",
      "Pair: ('listening', 'listened')\n",
      "Sim for indel: 70.58823529411764\n",
      "Sim for lev: 66.66666666666667\n",
      "\n",
      "Pair: ('listening', 'to')\n",
      "Sim for indel: 18.181818181818176\n",
      "Sim for lev: 11.111111111111116\n",
      "\n",
      "Pair: ('listening', 'enjoy')\n",
      "Sim for indel: 28.57142857142857\n",
      "Sim for lev: 22.22222222222222\n",
      "\n",
      "Pair: ('join', 'music')\n",
      "Sim for indel: 22.22222222222222\n",
      "Sim for lev: 19.999999999999996\n",
      "\n",
      "Pair: ('join', 'listen')\n",
      "Sim for indel: 40.0\n",
      "Sim for lev: 16.666666666666664\n",
      "\n",
      "Pair: ('join', 'listened')\n",
      "Sim for indel: 33.333333333333336\n",
      "Sim for lev: 12.5\n",
      "\n",
      "Pair: ('join', 'to')\n",
      "Sim for indel: 33.333333333333336\n",
      "Sim for lev: 25.0\n",
      "\n",
      "Pair: ('join', 'enjoy')\n",
      "Sim for indel: 44.44444444444444\n",
      "Sim for lev: 19.999999999999996\n",
      "\n",
      "Pair: ('music', 'listen')\n",
      "Sim for indel: 18.181818181818176\n",
      "Sim for lev: 16.666666666666664\n",
      "\n",
      "Pair: ('music', 'listened')\n",
      "Sim for indel: 15.384615384615385\n",
      "Sim for lev: 12.5\n",
      "\n",
      "Pair: ('music', 'to')\n",
      "Sim for indel: 0.0\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('music', 'enjoy')\n",
      "Sim for indel: 0.0\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('listen', 'listened')\n",
      "Sim for indel: 85.71428571428572\n",
      "Sim for lev: 75.0\n",
      "\n",
      "Pair: ('listen', 'to')\n",
      "Sim for indel: 25.0\n",
      "Sim for lev: 16.666666666666664\n",
      "\n",
      "Pair: ('listen', 'enjoy')\n",
      "Sim for indel: 36.36363636363637\n",
      "Sim for lev: 0.0\n",
      "\n",
      "Pair: ('listened', 'to')\n",
      "Sim for indel: 19.999999999999996\n",
      "Sim for lev: 12.5\n",
      "\n",
      "Pair: ('listened', 'enjoy')\n",
      "Sim for indel: 30.76923076923077\n",
      "Sim for lev: 12.5\n",
      "\n",
      "Pair: ('to', 'enjoy')\n",
      "Sim for indel: 28.57142857142857\n",
      "Sim for lev: 19.999999999999996\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pair in pairwise:\n",
    "    print(f\"Pair: {pair}\")\n",
    "    print(f\"Sim for indel: {similar_syntax_ver2(pair[0],pair[1],0)}\")\n",
    "    print(f\"Sim for lev: {similar_syntax_ver3(pair[0],pair[1],0)}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If we use indel: Setting enjoys and join as well as enjoy and join as a baseline**\n",
    "\n",
    "```\n",
    "Pair: ('enjoys', 'join')\n",
    "Sim for indel: 40.0\n",
    "Sim for lev: 33.333333333333336\n",
    "\n",
    "Pair: ('join', 'enjoy')\n",
    "Sim for indel: 44.44444444444444\n",
    "Sim for lev: 19.999999999999996\n",
    "\n",
    "Pair: ('mystic', 'listening')\n",
    "Sim for indel: 40.0\n",
    "Sim for lev: 33.333333333333336\n",
    "\n",
    "Pair: ('join', 'listen')\n",
    "Sim for indel: 40.0\n",
    "Sim for lev: 16.666666666666664\n",
    "```\n",
    "\n",
    "**If we use lev: Setting enjoys and join as well as enjoy and join as a baseline**\n",
    "\n",
    "```\n",
    "Pair: ('enjoys', 'join')\n",
    "Sim for indel: 40.0\n",
    "Sim for lev: 33.333333333333336\n",
    "\n",
    "Pair: ('join', 'enjoy')\n",
    "Sim for indel: 44.44444444444444\n",
    "Sim for lev: 19.999999999999996\n",
    "\n",
    "Pair: ('mystic', 'listening')\n",
    "Sim for indel: 40.0\n",
    "Sim for lev: 33.333333333333336\n",
    "\n",
    "Pair: ('mystic', 'listen')\n",
    "Sim for indel: 33.333333333333336\n",
    "Sim for lev: 33.333333333333336\n",
    "\n",
    "Pair: ('listening', 'join')\n",
    "Sim for indel: 30.76923076923077\n",
    "Sim for lev: 22.22222222222222\n",
    "\n",
    "Pair: ('listening', 'music')\n",
    "Sim for indel: 28.57142857142857\n",
    "Sim for lev: 22.22222222222222\n",
    "\n",
    "Pair: ('listening', 'enjoy')\n",
    "Sim for indel: 28.57142857142857\n",
    "Sim for lev: 22.22222222222222\n",
    "\n",
    "Pair: ('join', 'music')\n",
    "Sim for indel: 22.22222222222222\n",
    "Sim for lev: 19.999999999999996\n",
    "\n",
    "Pair: ('join', 'to')\n",
    "Sim for indel: 33.333333333333336\n",
    "Sim for lev: 25.0\n",
    "\n",
    "Pair: ('to', 'enjoy')\n",
    "Sim for indel: 28.57142857142857\n",
    "Sim for lev: 19.999999999999996\n",
    "```\n",
    "\n",
    "- We might have unwanted alignment if the threshold is set to low\n",
    "- Ideally we should get a high similarity for those words we want to be the same vice-versa\n",
    "- Realistically, the Nbest transcriptions should not be too far off\n",
    "- If there is a match, the pointers will move down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing all pairwise similarities for Jaccard similarity for our example sequences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(w1,w2):\n",
    "    doc1_set = set(w1)\n",
    "    doc2_set = set(w2)\n",
    "    intersection = doc1_set.intersection(doc2_set)\n",
    "    union = doc1_set.union(doc2_set)\n",
    "    return (len(intersection)/len(union))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair: ('I', 'enjoys')\n",
      "Sim for JS: 0.0\n",
      "\n",
      "Pair: ('I', 'am')\n",
      "Sim for JS: 0.0\n",
      "\n",
      "Pair: ('I', 'mystic')\n",
      "Sim for JS: 0.0\n",
      "\n",
      "Pair: ('I', 'listening')\n",
      "Sim for JS: 0.0\n",
      "\n",
      "Pair: ('I', 'join')\n",
      "Sim for JS: 0.0\n",
      "\n",
      "Pair: ('I', 'music')\n",
      "Sim for JS: 0.0\n",
      "\n",
      "Pair: ('I', 'listen')\n",
      "Sim for JS: 0.0\n",
      "\n",
      "Pair: ('I', 'listened')\n",
      "Sim for JS: 0.0\n",
      "\n",
      "Pair: ('I', 'to')\n",
      "Sim for JS: 0.0\n",
      "\n",
      "Pair: ('I', 'enjoy')\n",
      "Sim for JS: 0.0\n",
      "\n",
      "Pair: ('enjoys', 'am')\n",
      "Sim for JS: 0.0\n",
      "\n",
      "Pair: ('enjoys', 'mystic')\n",
      "Sim for JS: 20.0\n",
      "\n",
      "Pair: ('enjoys', 'listening')\n",
      "Sim for JS: 30.0\n",
      "\n",
      "Pair: ('enjoys', 'join')\n",
      "Sim for JS: 42.857142857142854\n",
      "\n",
      "Pair: ('enjoys', 'music')\n",
      "Sim for JS: 10.0\n",
      "\n",
      "Pair: ('enjoys', 'listen')\n",
      "Sim for JS: 33.33333333333333\n",
      "\n",
      "Pair: ('enjoys', 'listened')\n",
      "Sim for JS: 30.0\n",
      "\n",
      "Pair: ('enjoys', 'to')\n",
      "Sim for JS: 14.285714285714285\n",
      "\n",
      "Pair: ('enjoys', 'enjoy')\n",
      "Sim for JS: 83.33333333333334\n",
      "\n",
      "Pair: ('am', 'mystic')\n",
      "Sim for JS: 14.285714285714285\n",
      "\n",
      "Pair: ('am', 'listening')\n",
      "Sim for JS: 0.0\n",
      "\n",
      "Pair: ('am', 'join')\n",
      "Sim for JS: 0.0\n",
      "\n",
      "Pair: ('am', 'music')\n",
      "Sim for JS: 16.666666666666664\n",
      "\n",
      "Pair: ('am', 'listen')\n",
      "Sim for JS: 0.0\n",
      "\n",
      "Pair: ('am', 'listened')\n",
      "Sim for JS: 0.0\n",
      "\n",
      "Pair: ('am', 'to')\n",
      "Sim for JS: 0.0\n",
      "\n",
      "Pair: ('am', 'enjoy')\n",
      "Sim for JS: 0.0\n",
      "\n",
      "Pair: ('mystic', 'listening')\n",
      "Sim for JS: 30.0\n",
      "\n",
      "Pair: ('mystic', 'join')\n",
      "Sim for JS: 11.11111111111111\n",
      "\n",
      "Pair: ('mystic', 'music')\n",
      "Sim for JS: 57.14285714285714\n",
      "\n",
      "Pair: ('mystic', 'listen')\n",
      "Sim for JS: 33.33333333333333\n",
      "\n",
      "Pair: ('mystic', 'listened')\n",
      "Sim for JS: 30.0\n",
      "\n",
      "Pair: ('mystic', 'to')\n",
      "Sim for JS: 14.285714285714285\n",
      "\n",
      "Pair: ('mystic', 'enjoy')\n",
      "Sim for JS: 10.0\n",
      "\n",
      "Pair: ('listening', 'join')\n",
      "Sim for JS: 22.22222222222222\n",
      "\n",
      "Pair: ('listening', 'music')\n",
      "Sim for JS: 20.0\n",
      "\n",
      "Pair: ('listening', 'listen')\n",
      "Sim for JS: 85.71428571428571\n",
      "\n",
      "Pair: ('listening', 'listened')\n",
      "Sim for JS: 75.0\n",
      "\n",
      "Pair: ('listening', 'to')\n",
      "Sim for JS: 12.5\n",
      "\n",
      "Pair: ('listening', 'enjoy')\n",
      "Sim for JS: 20.0\n",
      "\n",
      "Pair: ('join', 'music')\n",
      "Sim for JS: 12.5\n",
      "\n",
      "Pair: ('join', 'listen')\n",
      "Sim for JS: 25.0\n",
      "\n",
      "Pair: ('join', 'listened')\n",
      "Sim for JS: 22.22222222222222\n",
      "\n",
      "Pair: ('join', 'to')\n",
      "Sim for JS: 20.0\n",
      "\n",
      "Pair: ('join', 'enjoy')\n",
      "Sim for JS: 50.0\n",
      "\n",
      "Pair: ('music', 'listen')\n",
      "Sim for JS: 22.22222222222222\n",
      "\n",
      "Pair: ('music', 'listened')\n",
      "Sim for JS: 20.0\n",
      "\n",
      "Pair: ('music', 'to')\n",
      "Sim for JS: 0.0\n",
      "\n",
      "Pair: ('music', 'enjoy')\n",
      "Sim for JS: 0.0\n",
      "\n",
      "Pair: ('listen', 'listened')\n",
      "Sim for JS: 85.71428571428571\n",
      "\n",
      "Pair: ('listen', 'to')\n",
      "Sim for JS: 14.285714285714285\n",
      "\n",
      "Pair: ('listen', 'enjoy')\n",
      "Sim for JS: 22.22222222222222\n",
      "\n",
      "Pair: ('listened', 'to')\n",
      "Sim for JS: 12.5\n",
      "\n",
      "Pair: ('listened', 'enjoy')\n",
      "Sim for JS: 20.0\n",
      "\n",
      "Pair: ('to', 'enjoy')\n",
      "Sim for JS: 16.666666666666664\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pair in pairwise:\n",
    "    print(f\"Pair: {pair}\")\n",
    "    print(f\"Sim for JS: {jaccard_similarity(pair[0],pair[1])}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If we use JS: Setting enjoys and join as well as enjoy and join as a baseline**\n",
    "\n",
    "```\n",
    "Pair: ('enjoys', 'join')\n",
    "Sim for JS: 42.857142857142854\n",
    "\n",
    "Pair: ('join', 'enjoy')\n",
    "Sim for JS: 50.0\n",
    "```\n",
    "\n",
    "Maybe try this simple method first\n",
    "\n",
    "Acceptability:\n",
    "- N-best transcriptions shouldn't be too far off hopefully\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research on Syntactic Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example input:\n",
    "\n",
    "\"I enjoys listening to music\"\n",
    "\n",
    "\"I enjoy listen music\"\n",
    "\n",
    "\"I join listening to music\"\n",
    "\n",
    "\"I enjoy listened mystic\"\n",
    "\n",
    "\"I am join listening music\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token Level Syntactic Similarity/Fuzzy Matching/Approximate string matching\n",
    "\n",
    "1. Levenshtein Distance/Edit distance. Count the minimum number of single character edits (insertion, deletion, substitutions) required to change one word into another\n",
    "- simple ratio, partial ratio (order matters), token sort ratio (don't care about order)\n",
    "- library: the fuzz\n",
    "- https://medium.com/@alphaiterations/fuzzy-matching-with-fuzzywuzzy-a-comprehensive-guide-04873f07de31\n",
    "- https://www.datacamp.com/tutorial/fuzzy-string-python\n",
    "- https://github.com/seatgeek/thefuzz\n",
    "\n",
    "2. Hamming distance\n",
    "- Count positions that don't match\n",
    "\n",
    "3. Soundex: Assigns a 4 character code to each name, first character is the initial letter of the name and the next three characters represent the leading (first three) consonant sounds. Useful for matching names with different spellings but similar pronunciations. Designed for the english language. More suitable for names?\n",
    "- library: jellyfish, phonetics\n",
    "- good with short names/strings\n",
    "\n",
    "4. Metaphone: Differences with soundex -> considers entire sound of the string instead of first few sounds\n",
    "- library: phonetics\n",
    "\n",
    "5. Double metaphone: Produces 2 encodings: One for the primary (most likely) pronunciation and one for an alternate (less common) pronunciation. Suitable for most english words, not just names. Basis for many spell checkers\n",
    "- https://moj-analytical-services.github.io/splink/topic_guides/comparisons/phonetic.html\n",
    "\n",
    "6. Use a combination with weightage\n",
    "- https://stackabuse.com/phonetic-similarity-of-words-a-vectorized-approach-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing a combination of indel ratio for the original words and indel ratio for the phonetic representations of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rapidfuzz in c:\\users\\user\\miniconda3\\envs\\myenv2\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: jellyfish in c:\\users\\user\\miniconda3\\envs\\myenv2\\lib\\site-packages (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install rapidfuzz\n",
    "!pip install jellyfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jellyfish\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "def similar_syntax(w1,w2,l1,threshold):\n",
    "    \"\"\"\n",
    "    Uses the indel similarity between the words and the indel similarity between the approx phonetic representations of the words\n",
    "    \"\"\"\n",
    "    sim = l1*fuzz.ratio(w1,w2) + (1-l1)*fuzz.ratio(jellyfish.metaphone(w1),jellyfish.metaphone(w2))\n",
    "    print(f\"The similarity is {sim}\")\n",
    "    if sim > threshold:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case: am enjoy\n",
      "The similarity is 0.0\n",
      "The words are not similar syntactically\n",
      "\n",
      "Test Case: join enjoy\n",
      "The similarity is 42.22222222222222\n",
      "The words are similar syntactically\n",
      "\n",
      "Test Case: listen listening\n",
      "The similarity is 80.0\n",
      "The words are similar syntactically\n",
      "\n",
      "Test Case: listen listened\n",
      "The similarity is 87.3015873015873\n",
      "The words are similar syntactically\n",
      "\n",
      "Test Case: listened listening\n",
      "The similarity is 71.65775401069519\n",
      "The words are similar syntactically\n",
      "\n",
      "Test Case: music mystic\n",
      "The similarity is 79.22077922077924\n",
      "The words are similar syntactically\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_cases = [('am','enjoy'),('join','enjoy'),('listen','listening'),('listen','listened'),('listened','listening'),('music','mystic')]\n",
    "\n",
    "for test in test_cases:\n",
    "    print(\"Test Case: \" + test[0] + \" \" + test[1])\n",
    "    if similar_syntax(test[0],test[1],0.5,35):\n",
    "        print(\"The words are similar syntactically\")\n",
    "    else:\n",
    "        print(\"The words are not similar syntactically\")\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing token level syntactic similarity via levenshtein and indel distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: thefuzz in c:\\users\\user\\miniconda3\\envs\\myenv2\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.0.0 in c:\\users\\user\\miniconda3\\envs\\myenv2\\lib\\site-packages (from thefuzz) (3.10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install thefuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indel Ratio test from thefuzz library \n",
      "\n",
      "Test Case: am enjoy\n",
      "0\n",
      " \n",
      "Test Case: join enjoy\n",
      "44\n",
      " \n",
      "Test Case: listen listening\n",
      "80\n",
      " \n",
      "Test Case: listen listened\n",
      "86\n",
      " \n",
      "Test Case: listened listening\n",
      "71\n",
      " \n",
      "Test Case: music mystic\n",
      "73\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# The Fuzz uses an indel similarity version \n",
    "# https://github.com/rapidfuzz/RapidFuzz/blob/main/api_differences.md\n",
    "# Check out this instead: https://github.com/rapidfuzz/RapidFuzz\n",
    "# https://github.com/rapidfuzz/RapidFuzz\n",
    "# https://rapidfuzz.github.io/RapidFuzz/Usage/distance/Levenshtein.html\n",
    "\n",
    "\n",
    "test_cases = [('am','enjoy'),('join','enjoy'),('listen','listening'),('listen','listened'),('listened','listening'),('music','mystic')]\n",
    "\n",
    "from thefuzz import fuzz as the_fuzz\n",
    "print(\"Indel Ratio test from thefuzz library \\n\")\n",
    "for test in test_cases:\n",
    "    print(\"Test Case: \" + test[0] + \" \" + test[1])\n",
    "    print(the_fuzz.ratio(test[0],test[1]))\n",
    "    print(\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rapidfuzz in c:\\users\\user\\miniconda3\\envs\\myenv2\\lib\\site-packages (3.10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indel Ratio test from rapidfuzz library \n",
      "\n",
      "Test Case: am enjoy\n",
      "0.0\n",
      " \n",
      "Test Case: join enjoy\n",
      "44.44444444444444\n",
      " \n",
      "Test Case: listen listening\n",
      "80.0\n",
      " \n",
      "Test Case: listen listened\n",
      "85.71428571428572\n",
      " \n",
      "Test Case: listened listening\n",
      "70.58823529411764\n",
      " \n",
      "Test Case: music mystic\n",
      "72.72727272727273\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from rapidfuzz import fuzz\n",
    "\n",
    "test_cases = [('am','enjoy'),('join','enjoy'),('listen','listening'),('listen','listened'),('listened','listening'),('music','mystic')]\n",
    "\n",
    "print(\"Indel Ratio test from rapidfuzz library \\n\")\n",
    "for test in test_cases:\n",
    "    print(\"Test Case: \" + test[0] + \" \" + test[1])\n",
    "    print(fuzz.ratio(test[0],test[1]))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indel Normalized Similarity test from rapidfuzz library \n",
      "\n",
      "Test Case: am enjoy\n",
      "0.0\n",
      " \n",
      "Test Case: join enjoy\n",
      "44.44444444444444\n",
      " \n",
      "Test Case: listen listening\n",
      "80.0\n",
      " \n",
      "Test Case: listen listened\n",
      "85.71428571428572\n",
      " \n",
      "Test Case: listened listening\n",
      "70.58823529411764\n",
      " \n",
      "Test Case: music mystic\n",
      "72.72727272727273\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from rapidfuzz.distance import Indel\n",
    "\n",
    "test_cases = [('am','enjoy'),('join','enjoy'),('listen','listening'),('listen','listened'),('listened','listening'),('music','mystic')]\n",
    "\n",
    "print(\"Indel Normalized Similarity test from rapidfuzz library \\n\")\n",
    "for test in test_cases:\n",
    "    print(\"Test Case: \" + test[0] + \" \" + test[1])\n",
    "    print(Indel.normalized_similarity(test[0],test[1])*100)\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Levenshtein Normalized Similarity test from rapidfuzz library \n",
      "\n",
      "Test Case: am enjoy\n",
      "0.0\n",
      " \n",
      "Test Case: join enjoy\n",
      "19.999999999999996\n",
      " \n",
      "Test Case: listen listening\n",
      "66.66666666666667\n",
      " \n",
      "Test Case: listen listened\n",
      "75.0\n",
      " \n",
      "Test Case: listened listening\n",
      "66.66666666666667\n",
      " \n",
      "Test Case: music mystic\n",
      "66.66666666666667\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from rapidfuzz.distance import Levenshtein\n",
    "\n",
    "test_cases = [('am','enjoy'),('join','enjoy'),('listen','listening'),('listen','listened'),('listened','listening'),('music','mystic')]\n",
    "\n",
    "print(\"Original Levenshtein Normalized Similarity test from rapidfuzz library \\n\")\n",
    "for test in test_cases:\n",
    "    print(\"Test Case: \" + test[0] + \" \" + test[1])\n",
    "    print(Levenshtein.normalized_similarity(test[0],test[1])*100)\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Levenshtein Distance test from pyphonetics library \n",
      "\n",
      "Test Case: am enjoy\n",
      "5\n",
      " \n",
      "Test Case: join enjoy\n",
      "4\n",
      " \n",
      "Test Case: listen listening\n",
      "3\n",
      " \n",
      "Test Case: listen listened\n",
      "2\n",
      " \n",
      "Test Case: listened listening\n",
      "3\n",
      " \n",
      "Test Case: music mystic\n",
      "2\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"Original Levenshtein Distance test from pyphonetics library \\n\")\n",
    "from pyphonetics.distance_metrics import levenshtein_distance\n",
    "for test in test_cases:\n",
    "    print(\"Test Case: \" + test[0] + \" \" + test[1])\n",
    "    ld = levenshtein_distance(test[0],test[1])\n",
    "    print(ld)\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\user\\miniconda3\\envs\\myenv2\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\user\\miniconda3\\envs\\myenv2\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\miniconda3\\envs\\myenv2\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\miniconda3\\envs\\myenv2\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\miniconda3\\envs\\myenv2\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\miniconda3\\envs\\myenv2\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Levenshtein Distance test from nltk library \n",
      "\n",
      "Test Case: am enjoy\n",
      "5\n",
      " \n",
      "Test Case: join enjoy\n",
      "4\n",
      " \n",
      "Test Case: listen listening\n",
      "3\n",
      " \n",
      "Test Case: listen listened\n",
      "2\n",
      " \n",
      "Test Case: listened listening\n",
      "3\n",
      " \n",
      "Test Case: music mystic\n",
      "2\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"Original Levenshtein Distance test from nltk library \\n\")\n",
    "import nltk\n",
    "for test in test_cases:\n",
    "    print(\"Test Case: \" + test[0] + \" \" + test[1])\n",
    "    ld = nltk.edit_distance(test[0],test[1])\n",
    "    print(ld)\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing token level syntactic similarity via calculating the original edit and indel distance between phonetic representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyphonetics in c:\\users\\user\\miniconda3\\envs\\myenv2\\lib\\site-packages (0.5.3)\n",
      "Requirement already satisfied: unidecode<2,>=1 in c:\\users\\user\\miniconda3\\envs\\myenv2\\lib\\site-packages (from pyphonetics) (1.3.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyphonetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soundex distance test from pyphonetics library\n",
      "am enjoy\n",
      "A500 E520\n",
      "Original Distance: 2\n",
      "Indel Similarity Ratio: 50.0\n",
      " \n",
      "join enjoy\n",
      "J500 E520\n",
      "Original Distance: 2\n",
      "Indel Similarity Ratio: 50.0\n",
      " \n",
      "listen listening\n",
      "L235 L235\n",
      "Original Distance: 0\n",
      "Indel Similarity Ratio: 100.0\n",
      " \n",
      "listen listened\n",
      "L235 L235\n",
      "Original Distance: 0\n",
      "Indel Similarity Ratio: 100.0\n",
      " \n",
      "listened listening\n",
      "L235 L235\n",
      "Original Distance: 0\n",
      "Indel Similarity Ratio: 100.0\n",
      " \n",
      "music mystic\n",
      "M220 M232\n",
      "Original Distance: 2\n",
      "Indel Similarity Ratio: 75.0\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"Soundex distance test from pyphonetics library\")\n",
    "from pyphonetics import Soundex\n",
    "soundex = Soundex()\n",
    "for test in test_cases:\n",
    "    print(test[0] + \" \" + test[1])\n",
    "    print(soundex.phonetics(test[0]) + \" \" + soundex.phonetics(test[1]))\n",
    "    ld = soundex.distance(test[0], test[1], metric='levenshtein')\n",
    "    print(f\"Original Distance: {ld}\")\n",
    "    print(f\"Indel Similarity Ratio: { fuzz.ratio(soundex.phonetics(test[0]),soundex.phonetics(test[1])) }\")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metaphone levenshtein distance test from pyphonetics library\n",
      "am enjoy\n",
      "AM ENJ\n",
      "Original Distance: 3\n",
      "Indel Similarity Ratio: 0.0\n",
      " \n",
      "join enjoy\n",
      "JN ENJ\n",
      "Original Distance: 2\n",
      "Indel Similarity Ratio: 40.0\n",
      " \n",
      "listen listening\n",
      "LSTN LSTNNK\n",
      "Original Distance: 2\n",
      "Indel Similarity Ratio: 80.0\n",
      " \n",
      "listen listened\n",
      "LSTN LSTNT\n",
      "Original Distance: 1\n",
      "Indel Similarity Ratio: 88.88888888888889\n",
      " \n",
      "listened listening\n",
      "LSTNT LSTNNK\n",
      "Original Distance: 2\n",
      "Indel Similarity Ratio: 72.72727272727273\n",
      " \n",
      "music mystic\n",
      "MSK MSTK\n",
      "Original Distance: 1\n",
      "Indel Similarity Ratio: 85.71428571428572\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"Metaphone levenshtein distance test from pyphonetics library\")\n",
    "from pyphonetics import Metaphone\n",
    "metaphone = Metaphone()\n",
    "for test in test_cases:\n",
    "    print(test[0] + \" \" + test[1])\n",
    "    print(metaphone.phonetics(test[0]) + \" \" + metaphone.phonetics(test[1]))\n",
    "    ld = metaphone.distance(test[0], test[1], metric='levenshtein')\n",
    "    print(f\"Original Distance: {ld}\")\n",
    "    print(f\"Indel Similarity Ratio: { fuzz.ratio(metaphone.phonetics(test[0]),metaphone.phonetics(test[1])) }\")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined Soundex distance test from pyphonetics library\n",
      "am enjoy\n",
      "A08 E0840\n",
      "Original Distance: 3\n",
      "Indel Similarity Ratio: 50.0\n",
      " \n",
      "join enjoy\n",
      "J408 E0840\n",
      "Original Distance: 4\n",
      "Indel Similarity Ratio: 44.44444444444444\n",
      " \n",
      "listen listening\n",
      "L703608 L703608084\n",
      "Original Distance: 3\n",
      "Indel Similarity Ratio: 82.35294117647058\n",
      " \n",
      "listen listened\n",
      "L703608 L70360806\n",
      "Original Distance: 2\n",
      "Indel Similarity Ratio: 87.5\n",
      " \n",
      "listened listening\n",
      "L70360806 L703608084\n",
      "Original Distance: 2\n",
      "Indel Similarity Ratio: 84.21052631578947\n",
      " \n",
      "music mystic\n",
      "M80303 M803603\n",
      "Original Distance: 1\n",
      "Indel Similarity Ratio: 92.3076923076923\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"Refined Soundex distance test from pyphonetics library\")\n",
    "from pyphonetics import RefinedSoundex\n",
    "rs = RefinedSoundex()\n",
    "for test in test_cases:\n",
    "    print(test[0] + \" \" + test[1])\n",
    "    print(rs.phonetics(test[0]) + \" \" + rs.phonetics(test[1]))\n",
    "    ld = rs.distance(test[0], test[1], metric='levenshtein')\n",
    "    print(f\"Original Distance: {ld}\")\n",
    "    print(f\"Indel Similarity Ratio: { fuzz.ratio(rs.phonetics(test[0]),rs.phonetics(test[1])) }\")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing token level syntactic similarity via phonetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: phonetics in c:\\users\\user\\miniconda3\\envs\\myenv2\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: pyphonetics in c:\\users\\user\\miniconda3\\envs\\myenv2\\lib\\site-packages (0.5.3)\n",
      "Requirement already satisfied: unidecode<2,>=1 in c:\\users\\user\\miniconda3\\envs\\myenv2\\lib\\site-packages (from pyphonetics) (1.3.8)\n",
      "Requirement already satisfied: jellyfish in c:\\users\\user\\miniconda3\\envs\\myenv2\\lib\\site-packages (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install phonetics\n",
    "!pip install pyphonetics\n",
    "!pip install jellyfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soundex test from phonetics library \n",
      "\n",
      "Test Case: am enjoy\n",
      "From phonetics library\n",
      "a500 e520\n",
      "From pyphonetics library\n",
      "A500 E520\n",
      "From jellyfish library\n",
      "A500 E520\n",
      " \n",
      "Test Case: join enjoy\n",
      "From phonetics library\n",
      "j050 e520\n",
      "From pyphonetics library\n",
      "J500 E520\n",
      "From jellyfish library\n",
      "J500 E520\n",
      " \n",
      "Test Case: listen listening\n",
      "From phonetics library\n",
      "l02305 l02305052\n",
      "From pyphonetics library\n",
      "L235 L235\n",
      "From jellyfish library\n",
      "L235 L235\n",
      " \n",
      "Test Case: listen listened\n",
      "From phonetics library\n",
      "l02305 l0230503\n",
      "From pyphonetics library\n",
      "L235 L235\n",
      "From jellyfish library\n",
      "L235 L235\n",
      " \n",
      "Test Case: listened listening\n",
      "From phonetics library\n",
      "l0230503 l02305052\n",
      "From pyphonetics library\n",
      "L235 L235\n",
      "From jellyfish library\n",
      "L235 L235\n",
      " \n",
      "Test Case: music mystic\n",
      "From phonetics library\n",
      "m0202 m02302\n",
      "From pyphonetics library\n",
      "M220 M232\n",
      "From jellyfish library\n",
      "M220 M232\n",
      " \n",
      "#####################################################################\n",
      "Metaphone test from phonetics library \n",
      "\n",
      "Test Case: am enjoy\n",
      "From phonetics library\n",
      "AM ANJ\n",
      "From pyphonetics library\n",
      "AM ENJ\n",
      "From jellyfish library\n",
      "AM ENJ\n",
      " \n",
      "Test Case: join enjoy\n",
      "From phonetics library\n",
      "JN ANJ\n",
      "From pyphonetics library\n",
      "JN ENJ\n",
      "From jellyfish library\n",
      "JN ENJ\n",
      " \n",
      "Test Case: listen listening\n",
      "From phonetics library\n",
      "LSTN LSTNNK\n",
      "From pyphonetics library\n",
      "LSTN LSTNNK\n",
      "From jellyfish library\n",
      "LSTN LSTNNK\n",
      " \n",
      "Test Case: listen listened\n",
      "From phonetics library\n",
      "LSTN LSTNT\n",
      "From pyphonetics library\n",
      "LSTN LSTNT\n",
      "From jellyfish library\n",
      "LSTN LSTNT\n",
      " \n",
      "Test Case: listened listening\n",
      "From phonetics library\n",
      "LSTNT LSTNNK\n",
      "From pyphonetics library\n",
      "LSTNT LSTNNK\n",
      "From jellyfish library\n",
      "LSTNT LSTNNK\n",
      " \n",
      "Test Case: music mystic\n",
      "From phonetics library\n",
      "MSK MSTK\n",
      "From pyphonetics library\n",
      "MSK MSTK\n",
      "From jellyfish library\n",
      "MSK MSTK\n",
      " \n",
      "#####################################################################\n"
     ]
    }
   ],
   "source": [
    "test_cases = [('am','enjoy'),('join','enjoy'),('listen','listening'),('listen','listened'),('listened','listening'),('music','mystic')]\n",
    "\n",
    "import phonetics\n",
    "from pyphonetics import Soundex\n",
    "import jellyfish\n",
    "soundex = Soundex()\n",
    "print(\"Soundex test from phonetics library \\n\")\n",
    "for test in test_cases:\n",
    "    print(\"Test Case: \" + test[0] + \" \" + test[1])\n",
    "    print(\"From phonetics library\")\n",
    "    print(phonetics.soundex(test[0]) + \" \" + phonetics.soundex(test[1]))\n",
    "    print(\"From pyphonetics library\")\n",
    "    print(soundex.phonetics(test[0]) + \" \" + soundex.phonetics(test[1]))\n",
    "    print(\"From jellyfish library\")\n",
    "    print(jellyfish.soundex(test[0]) + \" \" + jellyfish.soundex(test[1]))\n",
    "    print(\" \")\n",
    "\n",
    "\n",
    "print(\"#####################################################################\")\n",
    "\n",
    "from pyphonetics import Metaphone\n",
    "metaphone = Metaphone()\n",
    "print(\"Metaphone test from phonetics library \\n\")\n",
    "for test in test_cases:\n",
    "    print(\"Test Case: \" + test[0] + \" \" + test[1])\n",
    "    print(\"From phonetics library\")\n",
    "    print(phonetics.metaphone(test[0]) + \" \" + phonetics.metaphone(test[1]))\n",
    "    print(\"From pyphonetics library\")\n",
    "    print(metaphone.phonetics(test[0]) + \" \" + metaphone.phonetics(test[1]))\n",
    "    print(\"From jellyfish library\")\n",
    "    print(jellyfish.metaphone(test[0]) + \" \" + jellyfish.metaphone(test[1]))\n",
    "    print(\" \")\n",
    "\n",
    "print(\"#####################################################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RefinedSoundex test from pyphonetics library\n",
      "am enjoy\n",
      "From pyphonetics library\n",
      "A08 E0840\n",
      "Distance: 3\n",
      " \n",
      "join enjoy\n",
      "From pyphonetics library\n",
      "J408 E0840\n",
      "Distance: 4\n",
      " \n",
      "listen listening\n",
      "From pyphonetics library\n",
      "L703608 L703608084\n",
      "Distance: 3\n",
      " \n",
      "listen listened\n",
      "From pyphonetics library\n",
      "L703608 L70360806\n",
      "Distance: 2\n",
      " \n",
      "listened listening\n",
      "From pyphonetics library\n",
      "L70360806 L703608084\n",
      "Distance: 2\n",
      " \n",
      "music mystic\n",
      "From pyphonetics library\n",
      "M80303 M803603\n",
      "Distance: 1\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"RefinedSoundex test from pyphonetics library\")\n",
    "from pyphonetics import RefinedSoundex\n",
    "rs = RefinedSoundex()\n",
    "for test in test_cases:\n",
    "    print(test[0] + \" \" + test[1])\n",
    "    print(\"From pyphonetics library\")\n",
    "    print(rs.phonetics(test[0]) + \" \" + rs.phonetics(test[1]))\n",
    "    print(f\"Distance: {rs.distance(test[0], test[1])}\")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FuzzySoundex test from pyphonetics library\n",
      "am enjoy\n",
      "From pyphonetics library\n",
      "A5 E57\n",
      "Distance: 2\n",
      " \n",
      "join enjoy\n",
      "From pyphonetics library\n",
      "J5 E57\n",
      "Distance: 2\n",
      " \n",
      "listen listening\n",
      "From pyphonetics library\n",
      "L935 L93557\n",
      "Distance: 2\n",
      " \n",
      "listen listened\n",
      "From pyphonetics library\n",
      "L935 L9353\n",
      "Distance: 1\n",
      " \n",
      "listened listening\n",
      "From pyphonetics library\n",
      "L9353 L93557\n",
      "Distance: 2\n",
      " \n",
      "music mystic\n",
      "From pyphonetics library\n",
      "M99 M939\n",
      "Distance: 1\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"FuzzySoundex test from pyphonetics library\")\n",
    "from pyphonetics import FuzzySoundex\n",
    "fs = FuzzySoundex()\n",
    "for test in test_cases:\n",
    "    print(test[0] + \" \" + test[1])\n",
    "    print(\"From pyphonetics library\")\n",
    "    print(fs.phonetics(test[0]) + \" \" + fs.phonetics(test[1]))\n",
    "    print(f\"Distance: {fs.distance(test[0], test[1])}\")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Deprecated Code\n",
    "def align_new_seq(results,new_seq):\n",
    "    # Get the intersection of the sequences i.e. only the tokens and no padding tokens\n",
    "    seq_intersection = []\n",
    "    # For each column in the aligned sequences in the results,\n",
    "    # get the non-padding token, which is the same throughout the column\n",
    "    for col in zip(*results):\n",
    "        tokens = [t for t in col if t != 'Pad']\n",
    "        seq_intersection.append(tokens[0])\n",
    "\n",
    "    print(\"Results\")\n",
    "    for res in results:\n",
    "        print(res)\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "    print(\"Sequence Intersection: \")\n",
    "    print(seq_intersection)\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"New Sequence:\")\n",
    "    print(new_seq)\n",
    "    print(\"\")\n",
    "\n",
    "    # Align the new sequence with the sequence intersection. This ensures that we align the new sequence\n",
    "    # with all other sequences in the results\n",
    "    seq_intersection_aligned, new_seq_aligned = force_align(seq_intersection,new_seq)\n",
    "\n",
    "    print(\"Sequence Intersection aligned: \")\n",
    "    print(seq_intersection_aligned)\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"New Sequence Aligned:\")\n",
    "    print(new_seq_aligned)\n",
    "    print(\"\")\n",
    "\n",
    "    # Initialise the column pointer\n",
    "    col_pointer = 0\n",
    "    # Initialise the newly aligned results\n",
    "    aligned_results = [[] for _ in range(len(results))] \n",
    "\n",
    "    # For each token in the aligned sequence intersection\n",
    "    for k in range(len(seq_intersection_aligned)):\n",
    "        # Check if it at least one of the tokens in the column of the result matches the current sequence intersection token\n",
    "        aligned = False\n",
    "        # For each result, check if its value in the current column matches the current sequence intersection token\n",
    "        for i in range(len(results)): \n",
    "            if results[i][col_pointer]==seq_intersection_aligned[k]:\n",
    "                # This means that there is no new padding in the modified sequence intersection at this position,\n",
    "                # as it still uses the tokens from our aligned sequence\n",
    "                aligned = True \n",
    "                break\n",
    "        # If there was an alignment with the modified sequence intersection at this position\n",
    "        if aligned:\n",
    "             # Add the current tokens in the column to the newly aligned results and \n",
    "             # advance the column pointer to compare the next column\n",
    "             for i in range(len(results)):\n",
    "                 aligned_results[i].append(results[i][col_pointer])\n",
    "             col_pointer+=1\n",
    "        # If there was no alignment with the modified sequence intersection at this position\n",
    "        # it means we have to add a padding token\n",
    "        else:\n",
    "            for i in range(len(results)):\n",
    "                 aligned_results[i].append('Pad')\n",
    "\n",
    "    \n",
    "    aligned_results.append(new_seq_aligned)\n",
    "\n",
    "    print(\"Aligned Results\")\n",
    "    for res in aligned_results:\n",
    "        print(res)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "\n",
    "    return aligned_results\n",
    "\n",
    "\n",
    "def force_align_n_seqs(seqs):\n",
    "    # First force align 2 sequences\n",
    "    seq1,seq2 = force_align(seqs[0],seqs[1])\n",
    "\n",
    "    result = [seq1,seq2]\n",
    "\n",
    "    # Next, force align the sequences progressively\n",
    "    for seq in seqs[2:]:\n",
    "        result = align_new_seq(result,seq)\n",
    "        \n",
    "    return result\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
